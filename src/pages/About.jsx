import Section from '../components/SectionWrapper.jsx'

export default function About(){
  return (
    <Section title="About" subtitle="A brief intro">
      <div className="card" style={{padding:22}}>
        <p>
          I am a ğ‘¹ğ’†ğ’„ğ’†ğ’ğ’• ğ‘´ğ’‚ğ’”ğ’•ğ’†ğ’“â€™ğ’” ğ‘®ğ’“ğ’‚ğ’…ğ’–ğ’‚ğ’•ğ’† ğ’Šğ’ ğ‘«ğ’‚ğ’•ğ’‚ ğ‘ºğ’„ğ’Šğ’†ğ’ğ’„ğ’† & ğ‘¨ğ’‘ğ’‘ğ’ğ’Šğ’„ğ’‚ğ’•ğ’Šğ’ğ’ğ’” (ğ‘®ğ‘·ğ‘¨ 3.9) at the ğ‘¼ğ’ğ’Šğ’—ğ’†ğ’“ğ’”ğ’Šğ’•ğ’š ğ’‚ğ’• ğ‘©ğ’–ğ’‡ğ’‡ğ’‚ğ’ğ’ (ğ‘«ğ’†ğ’„ 2025) with 2.5+ ğ’šğ’†ğ’‚ğ’“ğ’” ğ’‚ğ’• ğ‘»ğ’‚ğ’•ğ’‚ ğ‘ªğ’ğ’ğ’”ğ’–ğ’ğ’•ğ’‚ğ’ğ’„ğ’š ğ‘ºğ’†ğ’“ğ’—ğ’Šğ’„ğ’†ğ’” (ğ‘»ğ‘ªğ‘º) as a ğ‘«ğ’‚ğ’•ğ’‚ ğ‘¨ğ’ğ’‚ğ’ğ’šğ’”ğ’•, ğ‘©ğ’Šğ’ˆ ğ‘«ğ’‚ğ’•ğ’‚ ğ‘·ğ’šğ’•ğ’‰ğ’ğ’ ğ‘«ğ’†ğ’—ğ’†ğ’ğ’ğ’‘ğ’†ğ’“, ğ’‚ğ’ğ’… ğ‘¨ğ‘° ğ‘«ğ’†ğ’—ğ’†ğ’ğ’ğ’‘ğ’†ğ’“, along with a client-facing capstone engagement with ğ‘´ğ’†ğ’…ğ’Šğ’‚ğ‘ºğ’‚ğ’ğ’†ğ’” ğ‘·ğ’ğ’–ğ’”.<br />

My expertise lies in ğ’…ğ’‚ğ’•ğ’‚ ğ’†ğ’ğ’ˆğ’Šğ’ğ’†ğ’†ğ’“ğ’Šğ’ğ’ˆ ğ’‚ğ’ğ’… ğ‘´ğ‘³ ğ’”ğ’šğ’”ğ’•ğ’†ğ’ğ’” - building ğ’”ğ’„ğ’‚ğ’ğ’‚ğ’ƒğ’ğ’† ğ’‘ğ’Šğ’‘ğ’†ğ’ğ’Šğ’ğ’†ğ’”, ğ’“ğ’†ğ’ğ’Šğ’‚ğ’ƒğ’ğ’† ğ‘¬ğ‘»ğ‘³/ğ’”ğ’•ğ’“ğ’†ğ’‚ğ’ğ’Šğ’ğ’ˆ ğ’˜ğ’ğ’“ğ’Œğ’‡ğ’ğ’ğ’˜ğ’”, ğ’‚ğ’ğ’… ğ’‘ğ’“ğ’ğ’…ğ’–ğ’„ğ’•ğ’Šğ’ğ’-ğ’ˆğ’“ğ’‚ğ’…ğ’† ğ’…ğ’†ğ’‘ğ’ğ’ğ’šğ’ğ’†ğ’ğ’•ğ’” across distributed platforms and applied analytics.<br />

At ğ‘»ğ’‚ğ’•ğ’‚ ğ‘ªğ’ğ’ğ’”ğ’–ğ’ğ’•ğ’‚ğ’ğ’„ğ’š ğ‘ºğ’†ğ’“ğ’—ğ’Šğ’„ğ’†ğ’” (ğ‘»ğ‘ªğ‘º), I:<br />
ğŸ”¹ Designed and deployed end-to-end ML pipelines using PySpark, TensorFlow, and PyTorch, improving deployment efficiency by 28% and increasing classification accuracy by 15%.<br />
ğŸ”¹ Optimized distributed workflows with Cloudera, Kafka, HDFS, and Kudu, reducing query latency by 40% and improving data reliability.<br />
ğŸ”¹ Managed and tuned distributed jobs (Spark/Flink) in production environments to improve processing performance and stability.<br />
ğŸ”¹ Supported production-grade deployments with Kubernetes, ensuring 99.9% uptime with robust debugging and model evaluation practices.<br />

At ğ‘¼ğ’ğ’Šğ’—ğ’†ğ’“ğ’”ğ’Šğ’•ğ’š ğ’‚ğ’• ğ‘©ğ’–ğ’‡ğ’‡ğ’‚ğ’ğ’, I strengthened expertise in:<br />
ğŸ”¹ Data Engineering / ML Infrastructure - deployment, evaluation, optimization, debugging, pipeline reliability.<br />
ğŸ”¹ Statistical Data Mining & Applied ML - modeling, feature engineering, and evaluation using real-world datasets.<br />
ğŸ”¹ Projects including Spark streaming pipelines (checkpoint recovery), graph algorithms (Dijkstra in PySpark), and graph analytics with Neo4j.<br />

At ğ‘´ğ’†ğ’…ğ’Šğ’‚ğ‘ºğ’‚ğ’ğ’†ğ’” ğ‘·ğ’ğ’–ğ’” (CDA 500 Capstone), I:<br />
ğŸ”¹ Built an end-to-end analytics pipeline to automate recurring reporting from monthly CSV/Excel datasets across business units.<br />
ğŸ”¹ Implemented data standardization + quality validation checks and delivered a Streamlit KPI dashboard with trend/anomaly views and forecasting summaries.<br />

ğŸ’¡ ğ‘ºğ’†ğ’†ğ’Œğ’Šğ’ğ’ˆ ğ’‡ğ’–ğ’ğ’-ğ’•ğ’Šğ’ğ’† ğ’“ğ’ğ’ğ’†ğ’” (ğ‘±ğ’‚ğ’ 2026) in Data Science / Data Engineering / Analytics Engineering / Machine Learning Engineering | Available immediately | F-1 OPT (STEM) - open to roles where I can build reliable pipelines and scalable ML systems in production.
        </p>
        <p className="mute">
          Machine Learning Engineer | Data Engineer | MS in Data Science @ SUNY Buffalo | Ex-TCS | Building Scalable AI Systems
        </p>
        <ul style={{ marginTop: 14, paddingLeft: 18, lineHeight: 1.7 }}>
          <li>Data Engineering: ETL/ELT, orchestration, reliability, and performance tuning</li>
          <li>ML Engineering: training â†’ deployment â†’ monitoring with production constraints</li>
          <li>Distributed systems: Spark pipelines, streaming workflows, and scalable infrastructure</li>
        </ul>
      </div>
    </Section>
  )
}
